{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN using Custom dataset in pytorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import random_split,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))#normalize the data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets.ImageFolder(root=\"D:\\\\images\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'dhoni', 'nature']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.4039, -0.3961, -0.3961,  ..., -0.5059, -0.5059, -0.5137],\n",
      "         [-0.3961, -0.4039, -0.4118,  ..., -0.4980, -0.4980, -0.5059],\n",
      "         [-0.3882, -0.4039, -0.4196,  ..., -0.4667, -0.4667, -0.4745],\n",
      "         ...,\n",
      "         [ 0.2078,  0.3176,  0.4431,  ..., -0.6627, -0.6157, -0.5765],\n",
      "         [ 0.5137,  0.4588,  0.3333,  ..., -0.6784, -0.6314, -0.5922],\n",
      "         [ 0.1059,  0.0667, -0.0118,  ..., -0.6706, -0.6314, -0.5922]],\n",
      "\n",
      "        [[-0.2627, -0.2549, -0.2549,  ..., -0.3490, -0.3490, -0.3569],\n",
      "         [-0.2549, -0.2627, -0.2706,  ..., -0.3412, -0.3412, -0.3490],\n",
      "         [-0.2627, -0.2784, -0.2941,  ..., -0.3255, -0.3255, -0.3333],\n",
      "         ...,\n",
      "         [ 0.2078,  0.3176,  0.4431,  ..., -0.7569, -0.7098, -0.6706],\n",
      "         [ 0.5137,  0.4588,  0.3333,  ..., -0.7725, -0.7255, -0.6863],\n",
      "         [ 0.1059,  0.0667, -0.0118,  ..., -0.7647, -0.7255, -0.6863]],\n",
      "\n",
      "        [[-0.0902, -0.0824, -0.0824,  ..., -0.1608, -0.1608, -0.1686],\n",
      "         [-0.0824, -0.0902, -0.0980,  ..., -0.1529, -0.1529, -0.1608],\n",
      "         [-0.0824, -0.0980, -0.1137,  ..., -0.1373, -0.1373, -0.1451],\n",
      "         ...,\n",
      "         [ 0.2706,  0.3804,  0.5059,  ..., -0.7412, -0.6941, -0.6549],\n",
      "         [ 0.5765,  0.5216,  0.3961,  ..., -0.7725, -0.7255, -0.6863],\n",
      "         [ 0.1686,  0.1294,  0.0510,  ..., -0.7647, -0.7255, -0.6863]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting 80% of data to training\n",
    "train_size=int(0.8*len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting remaining data to the test\n",
    "test_size=len(dataset)-train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,test_dataset=random_split(dataset,[train_size,test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=4,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        #formula =((w-f+2p)/s+)1\n",
    "        #w-width and height,f-filter,p-padding,s-stride\n",
    "\n",
    "        #input size :3 x 224 x224\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        #input size :12 x 112 x112\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        #input size :24 x 56 x 56\n",
    "        self.linear1=nn.Linear(24*56*56,128)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.linear2=nn.Linear(128,3)\n",
    "    \n",
    "    def forward(self,data):\n",
    "        out=self.conv1(data)\n",
    "        out=self.relu1(out)\n",
    "        out=self.pool(out)\n",
    "\n",
    "        out=self.conv2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.pool(out)\n",
    "\n",
    "        out=out.view(-1,24*56*56)#flatten layer \n",
    "\n",
    "        out=self.linear1(out)\n",
    "        out=self.relu3(out)\n",
    "        out=self.linear2(out)#we no need to mention softmax it automatically call it\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(),learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training part \n",
    "def neuralnetwork(model,criterion,optimizer,epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for input,labels in train_loader:\n",
    "            running_loss=0\n",
    "            output=model(input)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss=criterion(output,labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "        print(f\"the epochs are {epoch+1}/{epochs} and loss is {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the epochs are 1/15 and loss is 8.514940321089983e-08\n",
      "the epochs are 2/15 and loss is 2.2564576543767805e-07\n",
      "the epochs are 3/15 and loss is 2.1712790580100512e-06\n",
      "the epochs are 4/15 and loss is 1.0728674949080284e-06\n",
      "the epochs are 5/15 and loss is 1.2772401143073304e-07\n",
      "the epochs are 6/15 and loss is 0.0\n",
      "the epochs are 7/15 and loss is 1.1920909465905944e-07\n",
      "the epochs are 8/15 and loss is 1.958392203960102e-06\n",
      "the epochs are 9/15 and loss is 5.023784654310605e-07\n",
      "the epochs are 10/15 and loss is 3.405978889402052e-08\n",
      "the epochs are 11/15 and loss is 5.917858548595437e-07\n",
      "the epochs are 12/15 and loss is 9.110885912377853e-07\n",
      "the epochs are 13/15 and loss is 9.281188145645761e-07\n",
      "the epochs are 14/15 and loss is 1.0217926923620066e-07\n",
      "the epochs are 15/15 and loss is 4.257474373048353e-09\n"
     ]
    }
   ],
   "source": [
    "neuralnetwork(model,criterion,optimizer,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing part\n",
    "def testingpart(model,test_loader):\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in test_loader:\n",
    "            outputs=model(inputs)\n",
    "            print(outputs)\n",
    "            _,predicted=torch.max(outputs.data,1)#it return the max value in the output & also \n",
    "                                                 #which class they belong too\n",
    "            print(\"max values\",_)\n",
    "            print(\"class is\",predicted)\n",
    "            total=labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "        print(f\"accuracy of the model is {correct/total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-45.9515,  72.9120, -24.8831],\n",
      "        [  5.2437, -17.2137,   7.4001],\n",
      "        [ 16.1823, -17.5656,   3.7175],\n",
      "        [  7.9327, -10.4727,   2.2830]])\n",
      "max values tensor([72.9120,  7.4001, 16.1823,  7.9327])\n",
      "class is tensor([1, 2, 0, 0])\n",
      "tensor([[  2.2721,  -2.2164,   0.7290],\n",
      "        [-56.0631,  78.2264, -23.3306],\n",
      "        [  1.2630,  -8.7438,   8.4174]])\n",
      "max values tensor([ 2.2721, 78.2264,  8.4174])\n",
      "class is tensor([0, 1, 2])\n",
      "accuracy of the model is 1.0\n"
     ]
    }
   ],
   "source": [
    "testingpart(model,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
