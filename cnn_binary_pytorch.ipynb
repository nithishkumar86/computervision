{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CNN Binary search using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets.ImageFolder(root=\"D:\\\\testing\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "['car', 'nature']\n",
      "(tensor([[[-0.4039, -0.3961, -0.3961,  ..., -0.5059, -0.5059, -0.5137],\n",
      "         [-0.3961, -0.4039, -0.4118,  ..., -0.4980, -0.4980, -0.5059],\n",
      "         [-0.3882, -0.4039, -0.4196,  ..., -0.4667, -0.4667, -0.4745],\n",
      "         ...,\n",
      "         [ 0.2078,  0.3176,  0.4431,  ..., -0.6627, -0.6157, -0.5765],\n",
      "         [ 0.5137,  0.4588,  0.3333,  ..., -0.6784, -0.6314, -0.5922],\n",
      "         [ 0.1059,  0.0667, -0.0118,  ..., -0.6706, -0.6314, -0.5922]],\n",
      "\n",
      "        [[-0.2627, -0.2549, -0.2549,  ..., -0.3490, -0.3490, -0.3569],\n",
      "         [-0.2549, -0.2627, -0.2706,  ..., -0.3412, -0.3412, -0.3490],\n",
      "         [-0.2627, -0.2784, -0.2941,  ..., -0.3255, -0.3255, -0.3333],\n",
      "         ...,\n",
      "         [ 0.2078,  0.3176,  0.4431,  ..., -0.7569, -0.7098, -0.6706],\n",
      "         [ 0.5137,  0.4588,  0.3333,  ..., -0.7725, -0.7255, -0.6863],\n",
      "         [ 0.1059,  0.0667, -0.0118,  ..., -0.7647, -0.7255, -0.6863]],\n",
      "\n",
      "        [[-0.0902, -0.0824, -0.0824,  ..., -0.1608, -0.1608, -0.1686],\n",
      "         [-0.0824, -0.0902, -0.0980,  ..., -0.1529, -0.1529, -0.1608],\n",
      "         [-0.0824, -0.0980, -0.1137,  ..., -0.1373, -0.1373, -0.1451],\n",
      "         ...,\n",
      "         [ 0.2706,  0.3804,  0.5059,  ..., -0.7412, -0.6941, -0.6549],\n",
      "         [ 0.5765,  0.5216,  0.3961,  ..., -0.7725, -0.7255, -0.6863],\n",
      "         [ 0.1686,  0.1294,  0.0510,  ..., -0.7647, -0.7255, -0.6863]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(dataset.classes)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(0.8*len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=len(dataset)-train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,test_dataset=random_split(dataset,[train_size,test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=10,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBinary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #iput shape (10,3,224,224)\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=10,kernel_size=3,stride=1,padding=1)\n",
    "        self.batch1=nn.BatchNorm2d(num_features=10)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        #iput shape (10,10,112,112)\n",
    "        self.conv2=nn.Conv2d(in_channels=10,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        self.batch2=nn.BatchNorm2d(num_features=20)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        #input shape (10,20,56,56)\n",
    "        self.linear1=nn.Linear(20*56*56,120)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.linear2=nn.Linear(120,60)\n",
    "        self.relu4=nn.ReLU()\n",
    "        self.linear3=nn.Linear(60,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self,data):\n",
    "        out=self.conv1(data)\n",
    "        out=self.batch1(out)\n",
    "        out=self.relu1(out)\n",
    "        out=self.pool1(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.batch2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.pool2(out)\n",
    "\n",
    "        out=out.view(-1,20*56*56)#Flatten\n",
    "\n",
    "        out=self.linear1(out)\n",
    "        out=self.relu3(out)\n",
    "        out=self.linear2(out)\n",
    "        out=self.relu4(out)\n",
    "        out=self.linear3(out)\n",
    "        out=self.sigmoid(out)\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNNBinary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(),learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,train_loader,criterion,optimizer,epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss=0\n",
    "        for inputs,labels in train_loader:\n",
    "            labels=labels.unsqueeze(1).float()\n",
    "            #forward and output\n",
    "            outputs=model(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #loss calcute\n",
    "            loss=criterion(outputs,labels)\n",
    "\n",
    "            #backward propagation and weight updation\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "        print(f\"the epochs {epoch+1}/{epochs} and loss is {running_loss/len(train_loader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the epochs 1/50 and loss is 41.833504885435104\n",
      "the epochs 2/50 and loss is 50.83333396911621\n",
      "the epochs 3/50 and loss is 47.5\n",
      "the epochs 4/50 and loss is 42.5\n",
      "the epochs 5/50 and loss is 45.833333015441895\n",
      "the epochs 6/50 and loss is 45.833333015441895\n",
      "the epochs 7/50 and loss is 45.833333015441895\n",
      "the epochs 8/50 and loss is 49.16666603088379\n",
      "the epochs 9/50 and loss is 45.833333015441895\n",
      "the epochs 10/50 and loss is 49.16666603088379\n",
      "the epochs 11/50 and loss is 47.5\n",
      "the epochs 12/50 and loss is 45.833333015441895\n",
      "the epochs 13/50 and loss is 44.16666650772095\n",
      "the epochs 14/50 and loss is 45.833333015441895\n",
      "the epochs 15/50 and loss is 47.5\n",
      "the epochs 16/50 and loss is 49.16666603088379\n",
      "the epochs 17/50 and loss is 44.16666650772095\n",
      "the epochs 18/50 and loss is 50.83333396911621\n",
      "the epochs 19/50 and loss is 49.16666603088379\n",
      "the epochs 20/50 and loss is 47.5\n",
      "the epochs 21/50 and loss is 45.833333015441895\n",
      "the epochs 22/50 and loss is 47.5\n",
      "the epochs 23/50 and loss is 49.16666603088379\n",
      "the epochs 24/50 and loss is 50.83333396911621\n",
      "the epochs 25/50 and loss is 42.5\n",
      "the epochs 26/50 and loss is 45.833333015441895\n",
      "the epochs 27/50 and loss is 52.5\n",
      "the epochs 28/50 and loss is 50.83333396911621\n",
      "the epochs 29/50 and loss is 45.833333015441895\n",
      "the epochs 30/50 and loss is 50.83333396911621\n",
      "the epochs 31/50 and loss is 49.16666603088379\n",
      "the epochs 32/50 and loss is 45.833333015441895\n",
      "the epochs 33/50 and loss is 45.833333015441895\n",
      "the epochs 34/50 and loss is 44.16666650772095\n",
      "the epochs 35/50 and loss is 47.5\n",
      "the epochs 36/50 and loss is 47.5\n",
      "the epochs 37/50 and loss is 49.16666603088379\n",
      "the epochs 38/50 and loss is 50.83333396911621\n",
      "the epochs 39/50 and loss is 47.5\n",
      "the epochs 40/50 and loss is 45.833333015441895\n",
      "the epochs 41/50 and loss is 47.5\n",
      "the epochs 42/50 and loss is 47.5\n",
      "the epochs 43/50 and loss is 45.833333015441895\n",
      "the epochs 44/50 and loss is 45.833333015441895\n",
      "the epochs 45/50 and loss is 49.16666603088379\n",
      "the epochs 46/50 and loss is 45.833333015441895\n",
      "the epochs 47/50 and loss is 44.16666650772095\n",
      "the epochs 48/50 and loss is 47.5\n",
      "the epochs 49/50 and loss is 47.5\n",
      "the epochs 50/50 and loss is 44.16666650772095\n"
     ]
    }
   ],
   "source": [
    "training(model,train_loader,criterion,optimizer,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total accuracy is 0.5\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "total=0\n",
    "correct=0\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in test_loader:\n",
    "        labels=labels.unsqueeze(1).float()\n",
    "\n",
    "        pred=model(inputs)\n",
    "\n",
    "        total+=labels.size(0)\n",
    "        predict=(pred>0.5).float()\n",
    "        correct+=(predict==labels).sum().item()\n",
    "    accuracy=correct/total\n",
    "    print(f\"the total accuracy is {accuracy}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
